{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "hier , je disais qu’ une unanimité molle régnait sur le québec .    pas moyen de sortir du rang sans que les ténors du grand bêlement collectif nous remettent à l’ ordre .    il faut penser de telle façon , agir de telle façon et mener sa barque de telle façon , sinon les gardiens de la bonne parole qui officient au tribunal du peuple nous excommunient .    « les pendules à l’ heure »   prenez le chroniqueur de télé richard therrien , du journal le soleil .   dimanche soir , sur son blogue , therrien a publié un texte sur tout le monde en parle .    « le président du syndicat des employés du journal de montréal , le photographe reynald leblanc , a remis certaines pendules à l’ heure , a -t -il écrit . contrairement à ce qu’ a affirmé pierre - karl péladeau , les employés ne gagnent pas en moyenne 88 000 $ . c’ est plutôt le salaire maximum qu’ ils peuvent atteindre . on parle plutôt d’ autour de 50 000 $ en moyenne . »   therrien n’ a pas écrit : « selon le président du syndicat du journal de montréal , les employés ne gagneraient pas 88 000 $ » , comme l’ aurait fait n’ importe quel journaliste digne de ce nom .   il a écrit : « les employés ne gagnent pas 88 000 $ . »   il a publié ça comme si c’ était un fait objectif , coulé dans le béton .    pourquoi ? parce qu’ il avait les vrais chiffres en main , parce qu’ il a effectué une longue enquête lui permettant d’ authentifier l’ affirmation de reynald leblanc ?   non . parce que c’ est le président d’ un syndicat qui l’ a dit .   si c’ est le président d’ un syndicat qui l’ a dit , ça doit donc être vrai .   et après ça , ça se dit journaliste ...    parole d’ évangile   c’ est ça , l’ unanimité molle du québec .   un homme d’ affaires lance une affirmation — on utilise les guillemets et le futur antérieur afin d’ indiquer que c’ est sa vision des choses , et qu’ il faut prendre ses propos avec un gros grain de sel .   un chef syndical lance une affirmation — on écrit ça au présent et sans guillemets , comme si c’ était un fait indéniable .    l’ un est présumé coupable jusqu’ à preuve du contraire . l’ autre a notre bénédiction .    l' un a le fardeau de la preuve . l' autre a le bénéfice du doute .   pourquoi ce double standard ?   un politicien ou un entrepreneur ouvre la bouche , on se dit : « il est probablement en train de nous crosser . »   le porte-parole d’ un groupe de pression ou d’ un syndicat ouvre la bouche , on se dit : « cet homme dit la vérité . »   comme si les gens à gauche ne mentaient pas ! comme s’ ils ne tordaient pas les chiffres ! comme s’ ils étaient ontologiquement , essentiellement , fondamentalement bons !   comme si tout ce qui sortait de leur bouche était parole d’ évangile !    journalisme amateur   ce que richard therrien a fait est indigne d’ un journal comme la presse ou le soleil . pourtant , ça passe . c’ est publié . c’ est présenté comme un fait objectif .    mais essayez l’ inverse , vous . essayez de faire passer les dires d’ un entrepreneur ou d’ un politicien comme la vérité , sans aucune forme de vérification . on va vous tomber dessus en disant — avec raison — que vous faites un travail bâclé .   c’ est ça , le québec .   la droite est toujours coupable . la gauche est toujours innocente .    les patrons sont toujours menteurs . les syndicats sont toujours honnêtes .    les hommes sont toujours bourreaux . les femmes sont toujours victimes .    la cause est toujours entendue avant même que les faits ne soient présentés et que le procès commence .\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = set(text.split())\n",
    "word_to_idx = {word: i for i, word in enumerate(sorted(vocab))} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "265"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'!': 0,\n",
       " '$': 1,\n",
       " ',': 2,\n",
       " '-': 3,\n",
       " '-il': 4,\n",
       " '-t': 5,\n",
       " '.': 6,\n",
       " '...': 7,\n",
       " '000': 8,\n",
       " '50': 9,\n",
       " '88': 10,\n",
       " ':': 11,\n",
       " '?': 12,\n",
       " 'a': 13,\n",
       " 'affaires': 14,\n",
       " 'affirmation': 15,\n",
       " 'affirmé': 16,\n",
       " 'afin': 17,\n",
       " 'agir': 18,\n",
       " 'amateur': 19,\n",
       " 'antérieur': 20,\n",
       " 'après': 21,\n",
       " 'atteindre': 22,\n",
       " 'au': 23,\n",
       " 'aucune': 24,\n",
       " 'aurait': 25,\n",
       " 'authentifier': 26,\n",
       " 'autour': 27,\n",
       " 'autre': 28,\n",
       " 'avait': 29,\n",
       " 'avant': 30,\n",
       " 'avec': 31,\n",
       " 'barque': 32,\n",
       " 'blogue': 33,\n",
       " 'bonne': 34,\n",
       " 'bons': 35,\n",
       " 'bouche': 36,\n",
       " 'bourreaux': 37,\n",
       " 'bâclé': 38,\n",
       " 'bénédiction': 39,\n",
       " 'bénéfice': 40,\n",
       " 'béton': 41,\n",
       " 'bêlement': 42,\n",
       " 'cause': 43,\n",
       " 'ce': 44,\n",
       " 'certaines': 45,\n",
       " 'cet': 46,\n",
       " 'chef': 47,\n",
       " 'chiffres': 48,\n",
       " 'choses': 49,\n",
       " 'chroniqueur': 50,\n",
       " 'collectif': 51,\n",
       " 'comme': 52,\n",
       " 'commence': 53,\n",
       " 'contraire': 54,\n",
       " 'contrairement': 55,\n",
       " 'coulé': 56,\n",
       " 'coupable': 57,\n",
       " 'crosser': 58,\n",
       " 'c’': 59,\n",
       " 'dans': 60,\n",
       " 'de': 61,\n",
       " 'des': 62,\n",
       " 'dessus': 63,\n",
       " 'digne': 64,\n",
       " 'dimanche': 65,\n",
       " 'dires': 66,\n",
       " 'disais': 67,\n",
       " 'disant': 68,\n",
       " 'dit': 69,\n",
       " 'doit': 70,\n",
       " 'donc': 71,\n",
       " 'double': 72,\n",
       " 'doute': 73,\n",
       " 'droite': 74,\n",
       " 'du': 75,\n",
       " 'd’': 76,\n",
       " 'effectué': 77,\n",
       " 'employés': 78,\n",
       " 'en': 79,\n",
       " 'enquête': 80,\n",
       " 'entendue': 81,\n",
       " 'entrepreneur': 82,\n",
       " 'essayez': 83,\n",
       " 'essentiellement': 84,\n",
       " 'est': 85,\n",
       " 'et': 86,\n",
       " 'excommunient': 87,\n",
       " 'faire': 88,\n",
       " 'fait': 89,\n",
       " 'faites': 90,\n",
       " 'faits': 91,\n",
       " 'fardeau': 92,\n",
       " 'faut': 93,\n",
       " 'façon': 94,\n",
       " 'femmes': 95,\n",
       " 'fondamentalement': 96,\n",
       " 'forme': 97,\n",
       " 'futur': 98,\n",
       " 'gagnent': 99,\n",
       " 'gagneraient': 100,\n",
       " 'gardiens': 101,\n",
       " 'gauche': 102,\n",
       " 'gens': 103,\n",
       " 'grain': 104,\n",
       " 'grand': 105,\n",
       " 'gros': 106,\n",
       " 'groupe': 107,\n",
       " 'guillemets': 108,\n",
       " 'heure': 109,\n",
       " 'hier': 110,\n",
       " 'homme': 111,\n",
       " 'hommes': 112,\n",
       " 'honnêtes': 113,\n",
       " 'il': 114,\n",
       " 'ils': 115,\n",
       " 'importe': 116,\n",
       " 'indigne': 117,\n",
       " 'indiquer': 118,\n",
       " 'indéniable': 119,\n",
       " 'innocente': 120,\n",
       " 'inverse': 121,\n",
       " 'je': 122,\n",
       " 'journal': 123,\n",
       " 'journalisme': 124,\n",
       " 'journaliste': 125,\n",
       " 'jusqu’': 126,\n",
       " 'karl': 127,\n",
       " \"l'\": 128,\n",
       " 'la': 129,\n",
       " 'lance': 130,\n",
       " 'le': 131,\n",
       " 'leblanc': 132,\n",
       " 'les': 133,\n",
       " 'leur': 134,\n",
       " 'longue': 135,\n",
       " 'lui': 136,\n",
       " 'l’': 137,\n",
       " 'main': 138,\n",
       " 'mais': 139,\n",
       " 'maximum': 140,\n",
       " 'mener': 141,\n",
       " 'mentaient': 142,\n",
       " 'menteurs': 143,\n",
       " 'molle': 144,\n",
       " 'monde': 145,\n",
       " 'montréal': 146,\n",
       " 'moyen': 147,\n",
       " 'moyenne': 148,\n",
       " 'même': 149,\n",
       " 'ne': 150,\n",
       " 'nom': 151,\n",
       " 'non': 152,\n",
       " 'notre': 153,\n",
       " 'nous': 154,\n",
       " 'n’': 155,\n",
       " 'objectif': 156,\n",
       " 'officient': 157,\n",
       " 'on': 158,\n",
       " 'ontologiquement': 159,\n",
       " 'ordre': 160,\n",
       " 'ou': 161,\n",
       " 'ouvre': 162,\n",
       " 'parce': 163,\n",
       " 'parle': 164,\n",
       " 'parole': 165,\n",
       " 'pas': 166,\n",
       " 'passe': 167,\n",
       " 'passer': 168,\n",
       " 'patrons': 169,\n",
       " 'pendules': 170,\n",
       " 'penser': 171,\n",
       " 'permettant': 172,\n",
       " 'peuple': 173,\n",
       " 'peuvent': 174,\n",
       " 'photographe': 175,\n",
       " 'pierre': 176,\n",
       " 'plutôt': 177,\n",
       " 'politicien': 178,\n",
       " 'porte-parole': 179,\n",
       " 'pourquoi': 180,\n",
       " 'pourtant': 181,\n",
       " 'prendre': 182,\n",
       " 'prenez': 183,\n",
       " 'presse': 184,\n",
       " 'pression': 185,\n",
       " 'preuve': 186,\n",
       " 'probablement': 187,\n",
       " 'procès': 188,\n",
       " 'propos': 189,\n",
       " 'présent': 190,\n",
       " 'présenté': 191,\n",
       " 'présentés': 192,\n",
       " 'président': 193,\n",
       " 'présumé': 194,\n",
       " 'publié': 195,\n",
       " 'péladeau': 196,\n",
       " 'que': 197,\n",
       " 'quel': 198,\n",
       " 'qui': 199,\n",
       " 'québec': 200,\n",
       " 'qu’': 201,\n",
       " 'raison': 202,\n",
       " 'rang': 203,\n",
       " 'remettent': 204,\n",
       " 'remis': 205,\n",
       " 'reynald': 206,\n",
       " 'richard': 207,\n",
       " 'régnait': 208,\n",
       " 'sa': 209,\n",
       " 'salaire': 210,\n",
       " 'sans': 211,\n",
       " 'se': 212,\n",
       " 'sel': 213,\n",
       " 'selon': 214,\n",
       " 'ses': 215,\n",
       " 'si': 216,\n",
       " 'sinon': 217,\n",
       " 'soient': 218,\n",
       " 'soir': 219,\n",
       " 'soleil': 220,\n",
       " 'son': 221,\n",
       " 'sont': 222,\n",
       " 'sortait': 223,\n",
       " 'sortir': 224,\n",
       " 'standard': 225,\n",
       " 'sur': 226,\n",
       " 'syndical': 227,\n",
       " 'syndicat': 228,\n",
       " 'syndicats': 229,\n",
       " 's’': 230,\n",
       " 'telle': 231,\n",
       " 'texte': 232,\n",
       " 'therrien': 233,\n",
       " 'tomber': 234,\n",
       " 'tordaient': 235,\n",
       " 'toujours': 236,\n",
       " 'tout': 237,\n",
       " 'train': 238,\n",
       " 'travail': 239,\n",
       " 'tribunal': 240,\n",
       " 'télé': 241,\n",
       " 'ténors': 242,\n",
       " 'un': 243,\n",
       " 'unanimité': 244,\n",
       " 'une': 245,\n",
       " 'utilise': 246,\n",
       " 'va': 247,\n",
       " 'victimes': 248,\n",
       " 'vision': 249,\n",
       " 'vous': 250,\n",
       " 'vrai': 251,\n",
       " 'vrais': 252,\n",
       " 'vérification': 253,\n",
       " 'vérité': 254,\n",
       " '«': 255,\n",
       " '»': 256,\n",
       " 'à': 257,\n",
       " 'ça': 258,\n",
       " 'écrit': 259,\n",
       " 'étaient': 260,\n",
       " 'était': 261,\n",
       " 'évangile': 262,\n",
       " 'être': 263,\n",
       " '—': 264}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading previously created word embeddings using gensim\n",
    "vec_model_path = '/home/ngarneau/workspace/fastText/result/martibot-non-subword.vec'\n",
    "vec_model = KeyedVectors.load_word2vec_format(vec_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85832"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vec_model.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyEmbeddings(nn.Embedding):\n",
    "    def __init__(self, word_to_idx, embedding_dim):\n",
    "        super().__init__(len(word_to_idx), embedding_dim, padding_idx=0)\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.vocab_size = len(word_to_idx)\n",
    "        self.word_to_idx = word_to_idx\n",
    "\n",
    "    def set_item_embedding(self, idx, embedding):\n",
    "        self.weight.data[idx] = torch.FloatTensor(embedding)\n",
    "\n",
    "    def load_words_embeddings(self, vec_model):\n",
    "        for word in vec_model.index2word:\n",
    "            if word in self.word_to_idx:\n",
    "                idx = self.word_to_idx[word]\n",
    "                embedding = vec_model[word]\n",
    "                self.set_item_embedding(idx, embedding)\n",
    "                \n",
    "embeddings_layer = MyEmbeddings(word_to_idx, vec_model.vector_size)\n",
    "embeddings_layer.load_words_embeddings(vec_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.5302,  1.5655,  0.1522, -2.8967, -1.2558,  0.2743, -0.0139, -1.4988,\n",
       "          0.4073,  1.4930, -1.6155, -1.3601,  1.9467,  2.4351,  1.5251,  1.2024,\n",
       "         -1.5219, -0.7720,  2.8295, -1.1596, -1.8699,  1.9901, -1.2722,  0.4328,\n",
       "          0.2930,  1.9308, -0.9047,  0.9654,  0.7150, -2.0367, -0.1484,  1.4563,\n",
       "         -2.0209,  0.1235,  1.8981,  0.7131, -1.4859, -2.4792, -1.1683, -1.0590,\n",
       "         -2.1819, -2.0112, -3.5989, -1.5333, -0.0342, -1.3583, -1.1768, -2.1331,\n",
       "          0.8940,  1.7897, -1.9837,  0.7402, -0.3842,  2.2458,  2.1906,  0.5673,\n",
       "          0.8822,  1.6477, -2.0023, -0.7556, -4.4288,  2.9440,  1.6703, -0.0390,\n",
       "          2.5401, -0.0503, -1.2785, -1.1600, -1.0253,  0.3945, -1.1518, -1.9466,\n",
       "          2.4659,  1.8640,  2.4385,  0.5507, -1.2993,  2.9220,  0.2024, -0.0215,\n",
       "          2.1033, -3.2927, -2.5581,  0.0662,  0.8940, -0.1472,  1.4989,  0.4765,\n",
       "         -1.8072,  0.7090, -2.7256,  1.1555, -0.7732, -0.6978,  2.3139,  0.1457,\n",
       "         -1.3956,  1.4709,  1.7821,  0.2275]], grad_fn=<EmbeddingBackward>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_layer(torch.LongTensor([word_to_idx['fardeau']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True]], dtype=bool)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec_model['fardeau'] == embeddings_layer(torch.LongTensor([word_to_idx['fardeau']])).detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

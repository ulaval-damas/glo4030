{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "?nn.RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$h_t = \\text{tanh}(w_{ih} x_t + b_{ih} + w_{hh} h_{(t-1)} + b_{hh})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = nn.RNN(input_size=1, hidden_size=1, nonlinearity='relu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNN(1, 1)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Parameter containing:\n",
       " tensor([[0.7775]], requires_grad=True), Parameter containing:\n",
       " tensor([0.2025], requires_grad=True))"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn.weight_hh_l0, rnn.bias_hh_l0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Parameter containing:\n",
       " tensor([[-0.5602]], requires_grad=True), Parameter containing:\n",
       " tensor([0.0082], requires_grad=True))"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn.weight_ih_l0, rnn.bias_ih_l0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Parameter containing:\n",
       " tensor([0.], requires_grad=True), Parameter containing:\n",
       " tensor([0.], requires_grad=True))"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Init weights\n",
    "init.constant_(rnn.weight_hh_l0, 0.5)\n",
    "init.constant_(rnn.weight_ih_l0, 0.5)\n",
    "\n",
    "# Init biases\n",
    "init.constant_(rnn.bias_hh_l0, 0.0)\n",
    "init.constant_(rnn.bias_ih_l0, 0.0)\n",
    "rnn.bias_hh_l0, rnn.bias_ih_l0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.FloatTensor([[[1]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 1])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.5000]]], grad_fn=<StackBackward>),\n",
       " tensor([[[0.5000]]], grad_fn=<StackBackward>))"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$h_t = relu(W_{ih} \\cdot x_t + b_{ih} + W_{hh} \\cdot h_{t-1} + b_{hh})$\n",
    "\n",
    "$0.5 = max(0, 0.5 \\cdot 1 + 0 + 0 \\cdot 0.5 + 0)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2 = torch.FloatTensor([[[1]], [[1]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 1])"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.5000]],\n",
       " \n",
       "         [[0.7500]]], grad_fn=<StackBackward>),\n",
       " tensor([[[0.7500]]], grad_fn=<StackBackward>))"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hiddens, ht = rnn(x2)\n",
    "hiddens, ht"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calcul qui est fait:\n",
    "\n",
    "$h_t = relu(W_{ih} \\cdot x_t + b_{ih} + W_{hh} \\cdot h_{t-1} + b_{hh})$\n",
    "\n",
    "$0.75 = max(0, 0.5 \\cdot 1 + 0 + 0.5 \\cdot 0.5 + 0)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse d'un \"exploding gradient\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1.1000e+01]],\n",
      "\n",
      "        [[1.3200e+02]],\n",
      "\n",
      "        [[1.4630e+03]],\n",
      "\n",
      "        [[1.6104e+04]],\n",
      "\n",
      "        [[1.7716e+05]]], grad_fn=<StackBackward>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[62810.]]),\n",
       " tensor([[16105.]]),\n",
       " tensor([[[177155.]]], grad_fn=<StackBackward>))"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x3 = torch.ones((5, 1, 1), requires_grad=True)\n",
    "rnn = nn.RNN(input_size=1, hidden_size=1, nonlinearity='relu')\n",
    "init.constant_(rnn.weight_hh_l0, 11) # Important: Poids superieur a 1\n",
    "init.constant_(rnn.weight_ih_l0, 11)\n",
    "init.constant_(rnn.bias_hh_l0, 0.0)\n",
    "init.constant_(rnn.bias_ih_l0, 0.0)\n",
    "rnn.weight_hh_l0.grad, rnn.weight_ih_l0.grad = None, None\n",
    "hiddens, ht = rnn(x3)\n",
    "ht.backward(torch.ones(1, 1, 1))\n",
    "print(hiddens)\n",
    "rnn.weight_hh_l0.grad, rnn.weight_ih_l0.grad, ht"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1.6105e+05]],\n",
       "\n",
       "        [[1.4641e+04]],\n",
       "\n",
       "        [[1.3310e+03]],\n",
       "\n",
       "        [[1.2100e+02]],\n",
       "\n",
       "        [[1.1000e+01]]])"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x3.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse d'un \"vanishing gradient\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "x3 = torch.ones((20, 1, 1), requires_grad=True)\n",
    "rnn = nn.RNN(input_size=1, hidden_size=1, nonlinearity='tanh')\n",
    "# Init weights\n",
    "init.constant_(rnn.weight_hh_l0, 0.5) # Important: Poids inferieur a 1\n",
    "init.constant_(rnn.weight_ih_l0, 0.5)\n",
    "# Init biases\n",
    "init.constant_(rnn.bias_hh_l0, 0.0)\n",
    "init.constant_(rnn.bias_ih_l0, 0.0)\n",
    "rnn.weight_hh_l0.grad, rnn.weight_ih_l0.grad = None, None\n",
    "hiddens, ht = rnn(x3)\n",
    "ht.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4920]])"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn.weight_hh_l0.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7152]])"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn.weight_ih_l0.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.6879]]], grad_fn=<StackBackward>)"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ht"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[4.7499e-12]],\n",
       "\n",
       "        [[1.2079e-11]],\n",
       "\n",
       "        [[3.9541e-11]],\n",
       "\n",
       "        [[1.4371e-10]],\n",
       "\n",
       "        [[5.3918e-10]],\n",
       "\n",
       "        [[2.0406e-09]],\n",
       "\n",
       "        [[7.7405e-09]],\n",
       "\n",
       "        [[2.9380e-08]],\n",
       "\n",
       "        [[1.1154e-07]],\n",
       "\n",
       "        [[4.2344e-07]],\n",
       "\n",
       "        [[1.6076e-06]],\n",
       "\n",
       "        [[6.1032e-06]],\n",
       "\n",
       "        [[2.3171e-05]],\n",
       "\n",
       "        [[8.7967e-05]],\n",
       "\n",
       "        [[3.3397e-04]],\n",
       "\n",
       "        [[1.2679e-03]],\n",
       "\n",
       "        [[4.8136e-03]],\n",
       "\n",
       "        [[1.8275e-02]],\n",
       "\n",
       "        [[6.9380e-02]],\n",
       "\n",
       "        [[2.6340e-01]]])"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x3.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backprop through time (BPTT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.0023]],\n",
      "\n",
      "        [[0.0059]],\n",
      "\n",
      "        [[0.0194]],\n",
      "\n",
      "        [[0.0704]],\n",
      "\n",
      "        [[0.2642]],\n",
      "\n",
      "        [[0.0023]],\n",
      "\n",
      "        [[0.0059]],\n",
      "\n",
      "        [[0.0194]],\n",
      "\n",
      "        [[0.0704]],\n",
      "\n",
      "        [[0.2642]],\n",
      "\n",
      "        [[0.0023]],\n",
      "\n",
      "        [[0.0059]],\n",
      "\n",
      "        [[0.0194]],\n",
      "\n",
      "        [[0.0704]],\n",
      "\n",
      "        [[0.2642]],\n",
      "\n",
      "        [[0.0023]],\n",
      "\n",
      "        [[0.0059]],\n",
      "\n",
      "        [[0.0194]],\n",
      "\n",
      "        [[0.0704]],\n",
      "\n",
      "        [[0.2642]]])\n"
     ]
    }
   ],
   "source": [
    "x3 = torch.ones((20, 1, 1), requires_grad=True)\n",
    "rnn = nn.RNN(input_size=1, hidden_size=1, nonlinearity='tanh')\n",
    "# Init weights\n",
    "init.constant_(rnn.weight_hh_l0, 0.5) # Important: Poids inferieur a 1\n",
    "init.constant_(rnn.weight_ih_l0, 0.5)\n",
    "# Init biases\n",
    "init.constant_(rnn.bias_hh_l0, 0.0)\n",
    "init.constant_(rnn.bias_ih_l0, 0.0)\n",
    "\n",
    "rnn.weight_hh_l0.grad, rnn.weight_ih_l0.grad = None, None\n",
    "\n",
    "# Here comes the BPTT\n",
    "hiddens, ht = rnn(x3[:5])\n",
    "ht.backward()\n",
    "hiddens, ht = rnn(x3[5:10])\n",
    "ht.backward()\n",
    "hiddens, ht = rnn(x3[10:15])\n",
    "ht.backward()\n",
    "hiddens, ht = rnn(x3[15:20])\n",
    "ht.backward()\n",
    "print(x3.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augmentons la dimensionalit√©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNN(2, 3)"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn = nn.RNN(input_size=2, hidden_size=3, nonlinearity='tanh')\n",
    "rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Parameter containing:\n",
       " tensor([[-0.2226, -0.1108,  0.5350],\n",
       "         [ 0.1088,  0.2017,  0.2907],\n",
       "         [ 0.5027, -0.3554, -0.1394]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.2575,  0.3207,  0.5624], requires_grad=True))"
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn.weight_hh_l0, rnn.bias_hh_l0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Parameter containing:\n",
       " tensor([[ 0.2224, -0.1436],\n",
       "         [-0.4591, -0.0053],\n",
       "         [-0.2355,  0.2791]], requires_grad=True), Parameter containing:\n",
       " tensor([0.5437, 0.3929, 0.1203], requires_grad=True))"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn.weight_ih_l0, rnn.bias_ih_l0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.2178, 0.2392, 0.7638]],\n",
       " \n",
       "         [[0.5607, 0.0734, 0.7473]]], grad_fn=<StackBackward>),\n",
       " tensor([[[0.5607, 0.0734, 0.7473]]], grad_fn=<StackBackward>))"
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.FloatTensor([[[1, 2]], [[2, 3]]])\n",
    "rnn(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utilisons un LSTM pour contrer le vanishing gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "x3 = torch.ones((20, 1, 1), requires_grad=True)\n",
    "rnn = nn.LSTM(input_size=1, hidden_size=1)\n",
    "# Init weights\n",
    "init.constant_(rnn.weight_hh_l0, 0.5) # Important: Poids inferieur a 1\n",
    "init.constant_(rnn.weight_ih_l0, 0.5)\n",
    "# Init biases\n",
    "init.constant_(rnn.bias_hh_l0, 0.0)\n",
    "init.constant_(rnn.bias_ih_l0, 0.0)\n",
    "rnn.weight_hh_l0.grad, rnn.weight_ih_l0.grad = None, None\n",
    "hiddens, (ht, ct) = rnn(x3)\n",
    "ht.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0485],\n",
       "        [0.1067],\n",
       "        [0.1296],\n",
       "        [0.1642]])"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn.weight_hh_l0.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0783],\n",
       "        [0.1714],\n",
       "        [0.2099],\n",
       "        [0.2621]])"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn.weight_ih_l0.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.6286]]], grad_fn=<StackBackward>)"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ht"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0004]],\n",
       "\n",
       "        [[0.0005]],\n",
       "\n",
       "        [[0.0006]],\n",
       "\n",
       "        [[0.0008]],\n",
       "\n",
       "        [[0.0010]],\n",
       "\n",
       "        [[0.0013]],\n",
       "\n",
       "        [[0.0017]],\n",
       "\n",
       "        [[0.0023]],\n",
       "\n",
       "        [[0.0030]],\n",
       "\n",
       "        [[0.0040]],\n",
       "\n",
       "        [[0.0052]],\n",
       "\n",
       "        [[0.0069]],\n",
       "\n",
       "        [[0.0092]],\n",
       "\n",
       "        [[0.0122]],\n",
       "\n",
       "        [[0.0163]],\n",
       "\n",
       "        [[0.0216]],\n",
       "\n",
       "        [[0.0288]],\n",
       "\n",
       "        [[0.0388]],\n",
       "\n",
       "        [[0.0579]],\n",
       "\n",
       "        [[0.1483]]])"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x3.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

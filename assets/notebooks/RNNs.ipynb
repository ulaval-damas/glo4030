{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "?nn.RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$h_t = \\text{tanh}(w_{ih} x_t + b_{ih} + w_{hh} h_{(t-1)} + b_{hh})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = nn.RNN(input_size=1, hidden_size=1, nonlinearity='relu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNN(1, 1)"
      ]
     },
     "execution_count": 394,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Parameter containing:\n",
       " tensor([[-0.8162]], requires_grad=True), Parameter containing:\n",
       " tensor([0.4345], requires_grad=True))"
      ]
     },
     "execution_count": 395,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn.weight_hh_l0, rnn.bias_hh_l0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Parameter containing:\n",
       " tensor([[0.4128]], requires_grad=True), Parameter containing:\n",
       " tensor([-0.8132], requires_grad=True))"
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn.weight_ih_l0, rnn.bias_ih_l0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Parameter containing:\n",
       " tensor([0.], requires_grad=True), Parameter containing:\n",
       " tensor([0.], requires_grad=True))"
      ]
     },
     "execution_count": 397,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Init weights\n",
    "init.constant_(rnn.weight_hh_l0, 0.5)\n",
    "init.constant_(rnn.weight_ih_l0, 0.5)\n",
    "\n",
    "# Init biases\n",
    "init.constant_(rnn.bias_hh_l0, 0.0)\n",
    "init.constant_(rnn.bias_ih_l0, 0.0)\n",
    "rnn.bias_hh_l0, rnn.bias_ih_l0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.FloatTensor([[[1]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 1])"
      ]
     },
     "execution_count": 399,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.5000]]], grad_fn=<StackBackward>),\n",
       " tensor([[[0.5000]]], grad_fn=<StackBackward>))"
      ]
     },
     "execution_count": 400,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$h_t = relu(W_{ih} \\cdot x_t + b_{ih} + W_{hh} \\cdot h_{t-1} + b_{hh})$\n",
    "\n",
    "$0.5 = max(0, 0.5 \\cdot 1 + 0 + 0 \\cdot 0.5 + 0)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2 = torch.FloatTensor([[[1]], [[1]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 1])"
      ]
     },
     "execution_count": 402,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.5000]],\n",
       " \n",
       "         [[0.7500]]], grad_fn=<StackBackward>),\n",
       " tensor([[[0.7500]]], grad_fn=<StackBackward>))"
      ]
     },
     "execution_count": 403,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hiddens, ht = rnn(x2)\n",
    "hiddens, ht"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calcul qui est fait:\n",
    "\n",
    "$h_t = relu(W_{ih} \\cdot x_t + b_{ih} + W_{hh} \\cdot h_{t-1} + b_{hh})$\n",
    "\n",
    "$0.75 = max(0, 0.5 \\cdot 1 + 0 + 0.5 \\cdot 0.5 + 0)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse d'un \"exploding gradient\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1.1000e+01]],\n",
      "\n",
      "        [[1.3200e+02]],\n",
      "\n",
      "        [[1.4630e+03]],\n",
      "\n",
      "        [[1.6104e+04]],\n",
      "\n",
      "        [[1.7716e+05]],\n",
      "\n",
      "        [[1.9487e+06]],\n",
      "\n",
      "        [[2.1436e+07]],\n",
      "\n",
      "        [[2.3579e+08]],\n",
      "\n",
      "        [[2.5937e+09]],\n",
      "\n",
      "        [[2.8531e+10]]], grad_fn=<StackBackward>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[2.3084e+10]]),\n",
       " tensor([[2.5937e+09]]),\n",
       " tensor([[[2.8531e+10]]], grad_fn=<StackBackward>))"
      ]
     },
     "execution_count": 455,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x3 = torch.ones((10, 1, 1), requires_grad=True)\n",
    "rnn = nn.RNN(input_size=1, hidden_size=1, nonlinearity='relu')\n",
    "init.constant_(rnn.weight_hh_l0, 11)\n",
    "init.constant_(rnn.weight_ih_l0, 11)\n",
    "init.constant_(rnn.bias_hh_l0, 0.0)\n",
    "init.constant_(rnn.bias_ih_l0, 0.0)\n",
    "rnn.weight_hh_l0.grad, rnn.weight_ih_l0.grad = None, None\n",
    "hiddens, ht = rnn(x3)\n",
    "ht.backward(torch.ones(1, 1, 1))\n",
    "print(hiddens)\n",
    "rnn.weight_hh_l0.grad, rnn.weight_ih_l0.grad, ht"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[2.5937e+10]],\n",
       "\n",
       "        [[2.3579e+09]],\n",
       "\n",
       "        [[2.1436e+08]],\n",
       "\n",
       "        [[1.9487e+07]],\n",
       "\n",
       "        [[1.7716e+06]],\n",
       "\n",
       "        [[1.6105e+05]],\n",
       "\n",
       "        [[1.4641e+04]],\n",
       "\n",
       "        [[1.3310e+03]],\n",
       "\n",
       "        [[1.2100e+02]],\n",
       "\n",
       "        [[1.1000e+01]]])"
      ]
     },
     "execution_count": 456,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x3.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse d'un \"vanishing gradient\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [],
   "source": [
    "x3 = torch.ones((20, 1, 1), requires_grad=True)\n",
    "rnn = nn.RNN(input_size=1, hidden_size=1, nonlinearity='tanh')\n",
    "# Init weights\n",
    "init.constant_(rnn.weight_hh_l0, 0.5)\n",
    "init.constant_(rnn.weight_ih_l0, 0.5)\n",
    "# Init biases\n",
    "init.constant_(rnn.bias_hh_l0, 0.0)\n",
    "init.constant_(rnn.bias_ih_l0, 0.0)\n",
    "rnn.weight_hh_l0.grad, rnn.weight_ih_l0.grad = None, None\n",
    "hiddens, ht = rnn(x3)\n",
    "ht.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4920]])"
      ]
     },
     "execution_count": 458,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn.weight_hh_l0.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7152]])"
      ]
     },
     "execution_count": 459,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn.weight_ih_l0.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.6879]]], grad_fn=<StackBackward>)"
      ]
     },
     "execution_count": 460,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ht"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[4.7499e-12]],\n",
       "\n",
       "        [[1.2079e-11]],\n",
       "\n",
       "        [[3.9541e-11]],\n",
       "\n",
       "        [[1.4371e-10]],\n",
       "\n",
       "        [[5.3918e-10]],\n",
       "\n",
       "        [[2.0406e-09]],\n",
       "\n",
       "        [[7.7405e-09]],\n",
       "\n",
       "        [[2.9380e-08]],\n",
       "\n",
       "        [[1.1154e-07]],\n",
       "\n",
       "        [[4.2344e-07]],\n",
       "\n",
       "        [[1.6076e-06]],\n",
       "\n",
       "        [[6.1032e-06]],\n",
       "\n",
       "        [[2.3171e-05]],\n",
       "\n",
       "        [[8.7967e-05]],\n",
       "\n",
       "        [[3.3397e-04]],\n",
       "\n",
       "        [[1.2679e-03]],\n",
       "\n",
       "        [[4.8136e-03]],\n",
       "\n",
       "        [[1.8275e-02]],\n",
       "\n",
       "        [[6.9380e-02]],\n",
       "\n",
       "        [[2.6340e-01]]])"
      ]
     },
     "execution_count": 461,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x3.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Truncated Backprop through time (BPTT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [],
   "source": [
    "x3 = torch.ones((20, 1, 1), requires_grad=True)\n",
    "rnn = nn.RNN(input_size=1, hidden_size=1, nonlinearity='tanh')\n",
    "# Init weights\n",
    "init.constant_(rnn.weight_hh_l0, 0.5) # Important: Poids inferieur a 1\n",
    "init.constant_(rnn.weight_ih_l0, 0.5)\n",
    "# Init biases\n",
    "init.constant_(rnn.bias_hh_l0, 0.0)\n",
    "init.constant_(rnn.bias_ih_l0, 0.0)\n",
    "\n",
    "rnn.weight_hh_l0.grad, rnn.weight_ih_l0.grad = None, None\n",
    "\n",
    "# Here comes the BPTT\n",
    "\n",
    "hiddens, ht = rnn(x3[:5])\n",
    "ht.backward()\n",
    "hiddens, ht = rnn(x3[5:10])\n",
    "ht.backward()\n",
    "hiddens, ht = rnn(x3[10:15])\n",
    "ht.backward()\n",
    "hiddens, ht = rnn(x3[15:20])\n",
    "ht.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0023]],\n",
       "\n",
       "        [[0.0059]],\n",
       "\n",
       "        [[0.0194]],\n",
       "\n",
       "        [[0.0704]],\n",
       "\n",
       "        [[0.2642]],\n",
       "\n",
       "        [[0.0023]],\n",
       "\n",
       "        [[0.0059]],\n",
       "\n",
       "        [[0.0194]],\n",
       "\n",
       "        [[0.0704]],\n",
       "\n",
       "        [[0.2642]],\n",
       "\n",
       "        [[0.0023]],\n",
       "\n",
       "        [[0.0059]],\n",
       "\n",
       "        [[0.0194]],\n",
       "\n",
       "        [[0.0704]],\n",
       "\n",
       "        [[0.2642]],\n",
       "\n",
       "        [[0.0023]],\n",
       "\n",
       "        [[0.0059]],\n",
       "\n",
       "        [[0.0194]],\n",
       "\n",
       "        [[0.0704]],\n",
       "\n",
       "        [[0.2642]]])"
      ]
     },
     "execution_count": 463,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x3.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augmentons la dimensionalit√©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNN(2, 3)"
      ]
     },
     "execution_count": 434,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn = nn.RNN(input_size=2, hidden_size=3, nonlinearity='tanh')\n",
    "rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Parameter containing:\n",
       " tensor([[-0.2439, -0.2817,  0.2433],\n",
       "         [-0.2384,  0.2386,  0.0112],\n",
       "         [ 0.5688,  0.4414,  0.0746]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.0612, -0.4337,  0.0216], requires_grad=True))"
      ]
     },
     "execution_count": 435,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn.weight_hh_l0, rnn.bias_hh_l0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Parameter containing:\n",
       " tensor([[-0.1326,  0.3315],\n",
       "         [-0.2487,  0.5674],\n",
       "         [-0.5144, -0.5308]], requires_grad=True), Parameter containing:\n",
       " tensor([ 0.4380, -0.2485,  0.0262], requires_grad=True))"
      ]
     },
     "execution_count": 436,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn.weight_ih_l0, rnn.bias_ih_l0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 0.7198,  0.2010, -0.9101]],\n",
       " \n",
       "         [[ 0.5734,  0.3702, -0.9729]]], grad_fn=<StackBackward>),\n",
       " tensor([[[ 0.5734,  0.3702, -0.9729]]], grad_fn=<StackBackward>))"
      ]
     },
     "execution_count": 437,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.FloatTensor([[[1, 2]], [[2, 3]]])\n",
    "rnn(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utilisons un LSTM pour contrer le vanishing gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [],
   "source": [
    "x3 = torch.ones((20, 1, 1), requires_grad=True)\n",
    "rnn = nn.LSTM(input_size=1, hidden_size=1)\n",
    "# Init weights\n",
    "init.constant_(rnn.weight_hh_l0, 0.5) # Important: Poids inferieur a 1\n",
    "init.constant_(rnn.weight_ih_l0, 0.5)\n",
    "# Init biases\n",
    "init.constant_(rnn.bias_hh_l0, 0.0)\n",
    "init.constant_(rnn.bias_ih_l0, 0.0)\n",
    "rnn.weight_hh_l0.grad, rnn.weight_ih_l0.grad = None, None\n",
    "hiddens, (ht, ct) = rnn(x3)\n",
    "ht.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0485],\n",
       "        [0.1067],\n",
       "        [0.1296],\n",
       "        [0.1642]])"
      ]
     },
     "execution_count": 443,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn.weight_hh_l0.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0783],\n",
       "        [0.1714],\n",
       "        [0.2099],\n",
       "        [0.2621]])"
      ]
     },
     "execution_count": 445,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn.weight_ih_l0.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.6286]]], grad_fn=<StackBackward>)"
      ]
     },
     "execution_count": 446,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ht"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0004]],\n",
       "\n",
       "        [[0.0005]],\n",
       "\n",
       "        [[0.0006]],\n",
       "\n",
       "        [[0.0008]],\n",
       "\n",
       "        [[0.0010]],\n",
       "\n",
       "        [[0.0013]],\n",
       "\n",
       "        [[0.0017]],\n",
       "\n",
       "        [[0.0023]],\n",
       "\n",
       "        [[0.0030]],\n",
       "\n",
       "        [[0.0040]],\n",
       "\n",
       "        [[0.0052]],\n",
       "\n",
       "        [[0.0069]],\n",
       "\n",
       "        [[0.0092]],\n",
       "\n",
       "        [[0.0122]],\n",
       "\n",
       "        [[0.0163]],\n",
       "\n",
       "        [[0.0216]],\n",
       "\n",
       "        [[0.0288]],\n",
       "\n",
       "        [[0.0388]],\n",
       "\n",
       "        [[0.0579]],\n",
       "\n",
       "        [[0.1483]]])"
      ]
     },
     "execution_count": 447,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x3.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

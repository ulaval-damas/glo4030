---
layout: home
title: Accueil
---

## Horaire

| Jour     | Heure               | Local    |
|----------|---------------------|----------|
| Mardi    | 13h30 à 15h20       | PLT-XXXX |
| Mercredi | 12h30 à 13h20       | PLT-XXXX |
| Jeudi    | 13h30 à 15h20 (lab) | PLT-XXXX |


## Plan de cours

{:.collapsible}
- Semaine 0 : Mise à niveau : apprentissage automatique, probabilités, etc.

   Pour ce cours, nous prenons pour acquis que vous maîtrisez les concepts de base de l'apprentissage automatique, d'algèbre linéaire, et de probabilités. Pour ceux qui ont fait les préalables, vous devriez déjà avoir ces bases. Pour les autres, vous devrez faire des efforts supplémentaires pour acquérir ces fondements, et ce sur votre propre temps. Nous ne pouvons malheureusement pas utiliser du temps en classe pour expliquer ce qu'est l'apprentissage supervisé, le surapprentissage (overfit), ensemble de validation, etc.
   
   **Lectures dans le manuel :** Chapitre 2, 3, 4.
   
   Liens pour l'apprentissage automatique :
   - [Vidéo](http://videolectures.net/deeplearning2016_precup_machine_learning/) résumant le machine learning par Doina Precup
   - [Udacity : Introduction to Machine Learning](https://www.udacity.com/course/intro-to-machine-learning--ud120)
   - [Coursera : Machine Learning](https://www.class-central.com/mooc/835/coursera-machine-learning)
   
- Semaine 1 : Plan de cours, introduction, réseaux de bases

  **Lectures dans le manuel :** Chapitre 1, 6
  
  Nous verrons notamment quelles sont les innovations des 10 dernières années qui expliquent la résurgence des réseaux de neurones, en particulier l'apparition des réseaux profonds. 
  
  **Contenu détaillé :**
  - Introduction
  - Historique
  - Réseau feedforward (aval) de base : Multi-layer perceptron (MLP)
  - Importance de la dérivabilité
  
  **Acétates :** à venir.
  
  **Laboratoire :** Introduction à Pytorch
  
- Semaine 2 : Réseau feedforward, activations, graphes de calculs, backprop
  
  **Lectures dans le manuel :** Chapitre 6

  **Acétates :** à venir.
  
  **Laboratoire :** 
 
- Semaine 3 : Régularisation
  
  **Lectures dans le manuel :** Chapitre 7

- Semaine 4 : Initialisation et optimisation 
  
  **Lectures dans le manuel :** Chapitre 8

  **Acétates :** à venir.
  
  **Laboratoire :** 

- Semaine 5 : Réseaux à convolution I (CNN) 
  
  **Lectures dans le manuel :** Chapitre 9

  **Acétates :** à venir.
  
  **Laboratoire :** 

- Semaine 6 : Réseaux à convolution II (CNN) 
  
  **Lectures dans le manuel :** Chapitre 9

  **Acétates :** à venir.
  
  **Laboratoire :** 

## Livre
Le livre (obligatoire) est **Deep Learning** par Goodfellow, Benjio et Courville.
Il est également disponible en ligne au <http://www.deeplearningbook.org/>

<img src="https://mitpress.mit.edu/sites/default/files/9780262035613_0.jpg" width="350px">

## Liens

#### Deep Learning Glossary

- <http://www.wildml.com/deep-learning-glossary/>

#### Papers
- <https://github.com/terryum/awesome-deep-learning-papers>

#### Technos
Le framework utilisé dans le cours est PyTorch. Voici quelques liens utiles:

- <https://github.com/bharathgs/Awesome-pytorch-list>
- <https://github.com/aaron-xichen/pytorch-playground>

#### En savoir plus
- <http://cs231n.stanford.edu/index.html>
